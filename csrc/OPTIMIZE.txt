Optimization ideas: (2023-02-04)

Profiling with callgrind on a large flux file shows the following hotspots:
	51%: decoder::decode -> rabin_karp::find_match
	32%: get_MFM_train
	16%: get_flux_record

So the easiest way to make this faster would be to replace the MFM train with
run-length encoded data, i.e. instead of the output being "100010010001", it
would be "323". This would cut the length of the string Rabin-Karp has to
traverse by a third, and it would also speed up get_MFM_train and make
ordinal searching much easier if I want to implement that later; however,
clocking bits in decode_MFM would be much more of a hassle and the code
would be considerably more opaque. It may be the right way to go but it
feels wrong.

A significant part of the get_MFM_train calculation is the error stuff, but
it's a bit hard to tell just what's consuming time with all the inline
optimizations that -O3 does. There's also a bunch of overhead per push_back.
