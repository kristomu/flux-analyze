Optimization ideas: (2023-02-25)

Profiling with callgrind on a large flux file shows the following usage by
main() when optimizations are disabled:
	decoder::decode			38.81%
	get_MFM_train			21.12%
	MFM_train_data::operator+=	15.79%
	get_delta_coding		 6.69%
	get_flux_record			 6.95%
	<others>			10.64%

and optimized (possibly misleading):
	decoder::decode	(+ all R-K)     41.59%
	get_MFM_train			19.28%
	get_flux_record:		 9.07%
	get_delta_coding		 5.02%

Basically, this shows that the main hotspots are:
	1. Hash table lookups as part of Rabin-Karp.
	2. Rabin-Karp having to search over a longer haystack because MFM_train
		is a bitfield, not run length encoded.
	3. Memory shuffling due to the way the decoding process is modular
		(starting anew from each preamble) but also not (everything
		is concatenated into one higher-order stream).
	4. Duplication of effort running Rabin-Karp inside decoder::decode.

I can deal with point three (and probably will); I can't deal with 1 unless I
change the search algorithm, and I could deal with 2 by making MFM_train run
length encoded (or the number of half-clocks). But that would make the code
much harder to read, so I'm not going to. Finally, #4 will go away once I've
refactored properly.
